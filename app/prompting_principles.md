### Prompt Engineering Principles

| Advice Category | Principle (What to Do) | Why This Works (Benefit) | What It Is (Plain English) | Weaknesses / Limitations |
| :--- | :--- | :--- | :--- | :--- |
| **Level 1: Core Clarity** | **Be Specific & Constrained** | Helps the model stay focused and deliver relevant results by reducing ambiguity. | Clearly state what you want in detail: specify length, audience, format, tone, and key requirements (e.g., "exactly 3 bullet points, beginner-friendly, no technical jargon"). | Too many constraints can over-limit creativity or make the model refuse entirely. Being too specific in one dimension may also cause the model to ignore other important context. |
| **Level 1: Core Clarity** | **Define the Role** | Ensures the model responds with the right "voice" and expertise for the task. | Tell the model who it is (freelance writer, data analyst, grant reviewer, experienced teacher) to shape the answer style and depth. | Role-only prompts can feel generic without supporting context. Overuse of roles may confuse the model if they conflict with the actual task. |
| **Level 1: Core Clarity** | **Specify the Target Audience** | Tailors the writing style, tone, and detail to match who will read it. | Explicitly name the reader (e.g., "a 10-year-old," "a senior engineer," "someone unfamiliar with the topic") so the model adjusts complexity and terminology accordingly. | If the audience is unclear or irrelevant to the task, the model may guess wrong. Being overly specific about audience can also conflict with the task itself. |
| **Level 2: Structure & Input Design** | **Structure & Organize Inputs Clearly** | Makes prompts easy for the model to parse and follow. Combining clear formatting with semantic labels prevents confusion. | Separate instructions, examples, and data using formatting (### Instruction, ### Examples, ### Data) and semantic labels. Use backticks, headings, and clear sections so the model knows where each part begins. | Inconsistent or over-elaborate formatting can confuse rather than help. Too much structure in a simple prompt can feel rigid and unnecessary. |
| **Level 2: Structure & Input Design** | **Minimise Irrelevant Context** | Reduces hallucinations and keeps the model focused on the task. | Strip out background information that doesn't directly support your question. Keep only what the model needs to answer well. | Users often omit important context by accident, or misjudge what's "irrelevant." Trial-and-error is sometimes needed. Including context sometimes helps more than hurts, even if it seems tangential. |
| **Level 2: Structure & Input Design** | **Embed Examples of Bad Outputs to Avoid** | Guides the model on what not to do, improving output quality. | Show clear examples of poor outputs you want to avoid alongside examples of good outputs (e.g., "Good: uses simple language. Bad: uses technical jargon."). | If bad examples too closely resemble good ones, the model may get confused about what to do. Requires explicit labeling and clear differences between good/bad pairs. |
| **Level 3: Reasoning & Technique** | **Chain-of-Thought (CoT)** | Encourages structured reasoning and clearer explanations, reducing errors in complex tasks. | Ask the model to explain its reasoning step-by-step (e.g., "Walk me through your thinking" or "Show your work before the final answer"). | May produce longer, wordier answers. Does not reveal the model's internal reasoning—all visible output is still generated text, not a true "chain of thought." |
| **Level 3: Reasoning & Technique** | **Few-Shot Examples** | Gives the model a template to follow, especially helpful when instructions alone aren't enough. | Provide 2-3 sample Q&A pairs that show the desired structure, tone, and level of detail (e.g., examples of "good answers" for your task). | Examples can "anchor" the model too strongly to the sample, preventing better responses. Quality matters—poor examples can teach bad patterns. |
| **Level 3: Reasoning & Technique** | **Break Down Complex Tasks** | Avoids overload and improves quality by handling the work in stages. | Split the task into phases (e.g., "First, outline the main points. Then write the full response."). Have the model complete one step before moving to the next. | Requires back-and-forth interaction, which adds complexity. May need manual guidance between steps to keep the model on track. |
| **Level 3: Reasoning & Technique** | **Explicit Output Format** | Produces predictable, structured responses that are easy to reuse in automation or reporting. | Specify the exact format: "Return as a table," "Use JSON," "Bullet points with bold headers," etc. Be specific about structure. | Overly rigid formats can break if the content doesn't fit the mold. The model may sacrifice accuracy to meet a format requirement. |
| **Level 3: Reasoning & Technique** | **Generate Knowledge First** | Improves accuracy on knowledge-intensive tasks by grounding the model's reasoning. | Ask the model to first list what it knows about the topic, or state its assumptions, *before* answering (still single-turn within one prompt). | If the initial "knowledge" is wrong, errors compound throughout the answer. Works best when paired with evaluation criteria to catch hallucinations. |
| **Level 3: Reasoning & Technique** | **Set Clear Evaluation Criteria** | Helps judge output quality and guides the model to meet expectations. | Define what success looks like upfront—specify metrics for correctness, completeness, tone, or format (e.g., "must cite sources," "should be under 200 words," "use simple language"). | Requires users to define success before starting; vague criteria will be ignored. Users may also overthink what matters or specify contradictory criteria. |
| **Level 4: Refinement & Evaluation** | **Recursive Self-Improvement** | Improves quality by having the model review and refine its own responses. | Ask the model to write a first draft, then critique its own work against specific criteria, then revise (e.g., "Draft it. Then check: Is it clear? Accurate? Concise? Revise."). | Self-critique can be shallow without clear guidance. Adds extra tokens and output volume. Works best when paired with explicit evaluation criteria. |
| **Level 4: Refinement & Evaluation** | **Tree-of-Thoughts (ToT)** | Helps explore multiple solutions and evaluate them before choosing a final answer. | Ask the model to generate 3-5 possible approaches, list pros/cons for each, then select the best one (e.g., "Show me 3 ways to structure this answer, then pick the strongest."). | Can produce redundant or lengthy content. Requires you to review and decide which path is truly best—adds cognitive load. Best for high-stakes decisions. |
| **Level 4: Refinement & Evaluation** | **Constitutional Prompting** | Enforces adherence to rules or guidelines throughout the response. | Embed explicit rules the model must follow (e.g., "Always cite sources," "Use simple language," "No made-up facts"). State them clearly at the start. | Too many rules can confuse the model or cause conflicts (e.g., "be concise" vs. "cite everything"). Rules may be forgotten in long outputs without periodic reminders. |
| **Level 5: Meta-Thinking & Customization** | **Meta-Prompting** | Emphasizes reusable structural templates over content details, making prompts easier to adapt and standardize. | Design a prompt "template" that stays the same across many tasks, changing only the content details (e.g., a template for writing summaries, blog posts, or analyses). Reuse the structure. | Can feel abstract and hard to apply to one-off tasks. Risk of over-standardizing and losing task-specific nuance. Best for repeated, similar work. |

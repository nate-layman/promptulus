### Task Categorization Principles

| Advice Category | Principle | Why This Works | What It Is | Limitations |
| :--- | :--- | :--- | :--- | :--- |
| **Level 1: Task Nature** | **Identify the Core Output** | Reveals whether you're generating content/insights (LLM) or computing metrics/predictions (data science). | Ask: "What's the final deliverable?" If it's text, ideas, summaries, or creative content → LLM. If it's numbers, classifications, forecasts, or statistical measures → data science. | Some tasks produce both (e.g., "explain this prediction"), requiring hybrid approaches. |
| **Level 1: Task Nature** | **Assess Data Structure Requirements** | Structured, tabular data with clear features favors traditional ML; unstructured text/images favor LLMs. | Examine your inputs: CSV with columns? → Data science. Free-form text, documents, conversation? → LLM. Mixed? → Hybrid. | LLMs can work with structured data (via prompting), but traditional ML is often more efficient and interpretable for numeric tabular tasks. |
| **Level 1: Task Nature** | **Evaluate Domain Expertise Needs** | Tasks requiring deep reasoning about specialized topics may benefit from LLM knowledge; tasks requiring domain-specific models need data science. | If the task needs general reasoning, language understanding, or creativity → LLM. If it needs custom-trained models on your specific data → data science. | LLMs have broad but shallow knowledge; they can hallucinate. Data science models need training data but are more reliable within their domain. |
| **Level 2: Complexity Signals** | **Check for Ambiguity and Nuance** | High ambiguity and subjective interpretation favor LLMs; well-defined metrics favor data science. | Does the task involve interpreting tone, intent, or context? → LLM. Does it have clear success criteria (accuracy, RMSE, F1)? → Data science. | LLMs struggle with precise numerical tasks; data science struggles with subjective, open-ended problems. |
| **Level 2: Complexity Signals** | **Determine Volume and Speed Needs** | High-volume, real-time prediction tasks often favor data science; one-off or exploratory tasks favor LLMs. | Running millions of predictions per second? → Data science (batch ML). Ad-hoc analysis or content generation? → LLM. | LLMs can be slow and expensive at scale. Data science models require upfront training but are fast at inference. |
| **Level 2: Complexity Signals** | **Analyze Explainability Requirements** | If you need to explain *why* a decision was made with precise feature importance → data science. If narrative explanation suffices → LLM. | Regulated industry needing audit trails? → Data science (interpretable models). Summarizing for humans? → LLM. | LLMs can explain reasoning but may confabulate. Data science models (like linear regression, decision trees) offer true feature attribution. |
| **Level 3: Hybrid Indicators** | **Identify Multi-Stage Workflows** | Tasks with both analytical and generative components benefit from combining both approaches. | Example: "Predict customer churn (data science), then draft personalized retention emails (LLM)." Chain the outputs. | Requires orchestration between systems. More complexity to build and maintain. |
| **Level 3: Hybrid Indicators** | **Leverage LLMs for Feature Engineering** | LLMs can extract features from unstructured text, which then feed into ML models. | Use LLMs to summarize, extract entities, or classify text → feed outputs as features to traditional ML pipelines. | Adds latency and cost. LLM errors propagate to downstream models. |
| **Level 3: Hybrid Indicators** | **Use Data Science for Retrieval, LLMs for Synthesis** | Combine semantic search or clustering (data science) with LLM-generated summaries. | Retrieve relevant documents via embeddings/search (data science), then have LLM synthesize an answer (RAG pattern). | Requires both skill sets and infrastructure. Debugging is harder across the boundary. |
| **Level 4: Practical Constraints** | **Assess Available Resources** | LLMs require API costs or GPU infrastructure; data science requires labeled training data and ML expertise. | Do you have labeled data and ML engineers? → Data science. Do you have budget for LLM APIs and prompt engineers? → LLM. | Budget and team skills often determine feasibility more than technical fit. |
| **Level 4: Practical Constraints** | **Evaluate Iteration Speed** | LLMs allow rapid prototyping via prompt iteration; data science models require retraining cycles. | Need to test ideas quickly? → LLM (iterate prompts in minutes). Need production-grade performance? → Data science (train, validate, deploy). | LLM prototypes may not scale. Data science iteration is slower but yields robust models. |
| **Level 5: Strategic Guidance** | **Start with the Simplest Viable Approach** | Use LLMs for proof-of-concept, then move to data science if volume/cost/accuracy demands it. | Prototype with LLMs to validate the task is solvable, then build custom models if justified. | Premature optimization wastes time. But over-reliance on LLMs can incur long-term costs. |
| **Level 5: Strategic Guidance** | **Recognize When to Avoid Each** | Some tasks are better solved with neither—simple rules, heuristics, or deterministic logic may suffice. | If the task is fully rule-based (e.g., "flag transactions over $10k"), skip ML and LLMs entirely. Use code. | Both LLMs and data science add complexity. Simpler solutions are often better when applicable. |

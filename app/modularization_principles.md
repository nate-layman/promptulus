### Modularization Principles

| Advice Category | Principle | Why This Works | What It Is | Limitations |
| :--- | :--- | :--- | :--- | :--- |
| **Level 1: Framing the Task** | **Define the End Goal Before You Split** | Keeps every sub-prompt aligned with the same outcome, preventing fragmentation or drift. | Write one sentence describing the final deliverable (e.g., “Produce a clear, step-by-step guide for integrating Modulus into the Shiny app”). Use that as your north star when designing each prompt. | If the goal is vague, even perfectly modular steps won’t cohere. Spend time clarifying success criteria before splitting. |
| **Level 1: Framing the Task** | **Identify Distinct Cognitive Actions** | Reveals where natural breaks exist—planning, generating, summarizing, formatting, evaluating. | Underline every “and” or “then” in your big prompt. Each marks a potential discrete action (e.g., *research → outline → write → review*). | Over-splitting trivial actions adds overhead and context hand-off friction. Combine micro-steps when they clearly depend on shared context. |
| **Level 1: Framing the Task** | **Sequence from Abstraction to Detail** | Mirrors how humans and LLMs reason—start broad, then specialize. | Begin with prompts that clarify intent or structure (e.g., “Outline the main phases”), then follow with content generation or refinement prompts. | If earlier prompts are too abstract, later prompts lack concrete grounding. Provide enough context up front. |
| **Level 2: Chaining Logic** | **Define Inputs and Outputs Explicitly** | Prevents confusion and data loss between steps. | After each prompt, write what its output will be *used for* next. Example: “This outline will feed into the writing prompt.” Name these transitions. | Requires discipline. Skipping documentation of I/O quickly leads to broken chains when revising or debugging. |
| **Level 2: Chaining Logic** | **Use Stable Intermediate Artifacts** | Lets you review and correct partial work instead of re-running entire chains. | Save outputs like outlines, key points, or tables before moving on. Each becomes a checkpoint for iteration or reuse. | Adds storage or version management overhead if not automated. |
| **Level 2: Chaining Logic** | **Carry Forward Only Essential Context** | Keeps the model focused and token-efficient. | Instead of pasting full transcripts, summarize the previous step’s key facts or decisions. Feed that summary into the next prompt. | Over-compressing context can drop critical nuance. Strike a balance between brevity and fidelity. |
| **Level 3: Execution Strategy** | **Label Each Prompt by Function** | Clarifies purpose and supports automation later. | Prefix prompts with their role: `[PLAN]`, `[DRAFT]`, `[REVIEW]`, `[REFINE]`, etc. This helps both you and any orchestrator (human or code) keep order. | Too rigid a labeling system can feel artificial or discourage creative iteration. |
| **Level 3: Execution Strategy** | **Test the Smallest Viable Chain First** | Ensures your modular logic works before expanding complexity. | Implement a minimal 2–3-prompt flow end-to-end (e.g., outline → write → revise). Verify that each output flows cleanly into the next. | May not reveal scaling issues that appear only in longer chains. |
| **Level 3: Execution Strategy** | **Iterate by Swapping One Module at a Time** | Enables improvement without destabilizing the system. | Replace or refine a single step (e.g., rewrite the “outline” prompt) and re-run the chain to observe the effect. | Slow for very long pipelines—parallel evaluation tools may be needed. |
| **Level 4: Review & Optimization** | **Evaluate Each Step Independently** | Makes debugging and pedagogy easier—learners can see where reasoning fails. | After running the chain, inspect each output. Ask: “Did this step accomplish its goal before the next one began?” | Adds manual review overhead unless you automate evaluation. |
| **Level 4: Review & Optimization** | **Document the Prompt Flow Visually** | Converts a hidden reasoning chain into a transparent learning tool. | Create a simple diagram: boxes for prompts, arrows for outputs. Label transitions (“Outline → Draft → Review”). | Becomes stale if the chain evolves but the diagram doesn’t. |
| **Level 5: Meta-Learning** | **Generalize the Pattern** | Teaches transfer: users learn how to modularize any complex task, not just this one. | After building one modular chain, abstract the pattern (“research → plan → generate → evaluate”) and reapply it elsewhere. | Over-generalization can ignore domain-specific nuances; adapt patterns thoughtfully. |
| **Level 5: Meta-Learning** | **Reflect and Recurse** | Reinforces that modularization itself can be modularized—each principle is a unit of thought. | Ask: “Which part of my workflow could itself be broken into smaller prompts?” Teaching this self-awareness is the final step of mastery. | Can become infinite regress; always anchor recursion to practical improvement. |

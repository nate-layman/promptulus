## üõ†Ô∏è Actionable Prompt Engineering Principles for User Advice  
*(With Weaknesses/Limitations Added)*

| Advice Category | Principle (What to Do) | Why This Works (Benefit) | What It Is (Plain English) | Weaknesses / Limitations |
| :--- | :--- | :--- | :--- | :--- |
| **Level 1: Fundamentals (Clarity)** | **Be Specific & Constrained** | Helps the model stay focused and deliver relevant results by reducing ambiguity. | Clearly stating what you want in detail (e.g., length, audience, format). | Too many constraints can over-limit creativity or make the model refuse a task entirely (‚ÄúI can only do X‚Äù). |
| | **Define the Role** | Ensures the model responds with the right ‚Äúvoice‚Äù and expertise for the task. | Tell the model who it is (freelance writer, data analyst, grant reviewer) to shape the answer style. | Overuse of roles can lead to "role confusion" or generic results if not supported by useful context. |
| | **Specify the Target Audience** | Tailors the writing style, tone, and detail to match who will read it. | Explaining who the final reader is (e.g., beginner, researcher) to adjust complexity and tone. | If the audience is unclear or irrelevant, the model may guess wrong, resulting in poor tone matching. |
| **Level 2: Reasoning (Reliability)** | **Chain-of-Thought (CoT)** | Encourages structured reasoning and clearer explanations, reducing errors in complex tasks. | Asking the model to explain its steps as it works through a complex question. | May lead to longer, more verbose answers; does *not* reveal internal reasoning (all visible output is generated). |
| | **Few-Shot Examples** | Gives the model a template to follow, especially helpful when instructions alone aren‚Äôt enough. | Showing sample answers so the model copies the structure, tone, or format. | Examples may ‚Äúanchor‚Äù or bias the model too heavily toward the sample‚Äîeven when a better option exists. |
| | **Break Down Complex Tasks** | Avoids overload and improves quality by handling the work in stages. | Have the model do one phase at a time (e.g. outline first, content second). | Adds more back-and-forth steps and may require active guidance between steps. |
| | **Explicit Output Format** | Produces predictable, structured responses that are easy to reuse in automation or reporting. | Asking for a table, bullet points, JSON, etc. to make responses machine-readable. | If the format is too rigid or complex, the model may produce invalid or partially incorrect structure. |
| **Level 3: Advanced (Decision Support & Automation)** | **Recursive Self-Improvement** | Improves quality by having the model review and refine its own responses. | Ask the model to write a draft, critique it, then revise based on the critique. | Self-critique may be shallow unless guided by clear criteria; adds extra output volume. |
| | **Elicit Clarification** | Ensures the model has all necessary information before answering. | Telling the model to ask questions before responding if it‚Äôs unsure. | Adds interaction overhead; may lead to unnecessary clarification questions for simple tasks. |
| | **Tree-of-Thoughts (ToT)** | Helps explore multiple solutions and evaluate them before choosing a final answer. | Generating several options first, with pros and cons, before selecting the best one. | Can produce redundant or repetitive content. Requires careful review to select the best path forward. |
| | **Constitutional Prompting** | Enforces adherence to rules or guidelines throughout the response. | Embedding rules (like ‚Äúno jargon,‚Äù ‚Äúalways cite sources‚Äù) that the model must follow. | Too many rules may confuse or slow the model, and can sometimes conflict or be forgotten without reminders. |
| **Additional Principles** | **Use Delimiters to Organize Inputs** | Helps the model parse instructions, examples, and content clearly. | Separate instructions, examples, and data using backticks, quotes, or headings (e.g., ### Instruction ###). | Misuse or inconsistent formatting can lead to confusion; requires discipline in structuring prompts. |
| | **Avoid Ambiguous Pronouns and References** | Reduces misunderstanding in longer prompts by clearly identifying subjects. | Use explicit nouns instead of pronouns like ‚Äúit‚Äù or ‚Äúthat.‚Äù | Writing may become repetitive; users may overlook ambiguous references. |
| | **Embed Examples of Bad Outputs to Avoid** | Guides the model on what not to do, improving output quality. | Show examples of common mistakes or undesired outputs. | Can confuse the model if examples are too similar to good outputs; requires clear distinction between good and bad. |
| | **Instruction First** | Placing the main task at the beginning helps the model understand the goal early. | Start prompts with the task before providing context or data. | If the instruction is too brief or vague, the model may misinterpret; users may struggle to condense instructions. |
| | **Minimise Irrelevant Context** | Reduces hallucinations and keeps the model focused on the task. | Include only necessary background; avoid clutter. | Users may omit important details by mistake or include too much, overloading the model. |
| | **Adapt to the Model / Version** | Tailoring prompts to the specific model improves output quality. | Adjust phrasing, length, and style depending on the model‚Äôs capabilities. | Adds complexity; non-experts may not know the model version or differences; reduces portability. |
| | **Set Clear Evaluation Criteria** | Helps judge output quality and guides the model to meet expectations. | Define metrics for correctness, completeness, tone, and format. | Requires users to define success upfront; vague criteria may be ignored or misinterpreted. |
| | **Generate Knowledge First** | Helps the model operate with better factual grounding, improving accuracy on knowledge-intensive tasks. | Ask the model to generate relevant background facts or knowledge *before* you ask the main question or task. | Adds extra prompts/interaction; if the generated knowledge is incorrect it may hurt instead of help; requires user review of the knowledge step. |
| | **Prompt Chaining** | Splits a big task into smaller subtasks and uses the output of one prompt as input to the next, improving reliability and controllability. | First ask the model a sub-question, then feed that result into a next prompt for the main task. | Requires managing multiple prompts and tracking outputs; non-experts may find chains complex or hard to debug. |
| | **Define Prompt Elements Explicitly** | Structuring prompts with clear labels for instruction, context, input, and output improves comprehension. | Explicitly separate task, data, and expected output sections for clarity. | Non-experts may struggle to identify the correct sections; over-structuring may feel rigid. |
| | **Use Self-Consistency / Multiple Reasoning Paths** | Generates multiple candidate answers or reasoning chains and selects the most consistent result, improving reliability. | Ask the model to provide multiple reasoning paths and choose the one most internally consistent. | More complex workflow, more compute/time; may be overkill for simple tasks; harder for non-experts to implement. |
| | **Use Meta-Prompting (Structure-Over-Content)** | Emphasizes reusable structural templates over content details, making prompts easier to adapt and standardize. | Focus on the form or template of prompts for repeated tasks, not just the words. | Can feel abstract or too rigid for one-off tasks; may confuse users if not explained clearly. |

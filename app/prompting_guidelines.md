### Prompt Engineering Principles

| Advice Category | Principle (What to Do) | Why This Works (Benefit) | What It Is (Plain English) | Weaknesses / Limitations |
| :--- | :--- | :--- | :--- | :--- |
| **Level 1: Fundamentals (Clarity)** | **Be Specific & Constrained** | Helps the model stay focused and deliver relevant results by reducing ambiguity. | Clearly stating what you want in detail (e.g., length, audience, format). | Too many constraints can over-limit creativity or make the model refuse a task entirely (“I can only do X”). |
| | **Define the Role** | Ensures the model responds with the right “voice” and expertise for the task. | Tell the model who it is (freelance writer, data analyst, grant reviewer) to shape the answer style. | Overuse of roles can lead to "role confusion" or generic results if not supported by useful context. |
| | **Specify the Target Audience** | Tailors the writing style, tone, and detail to match who will read it. | Explaining who the final reader is (e.g., beginner, researcher) to adjust complexity and tone. | If the audience is unclear or irrelevant, the model may guess wrong, resulting in poor tone matching. |
| **Level 2: Reasoning (Reliability)** | **Chain-of-Thought (CoT)** | Encourages structured reasoning and clearer explanations, reducing errors in complex tasks. | Asking the model to explain its steps as it works through a complex question. | May lead to longer, more verbose answers; does *not* reveal internal reasoning (all visible output is generated). |
| | **Few-Shot Examples** | Gives the model a template to follow, especially helpful when instructions alone aren’t enough. | Showing sample answers so the model copies the structure, tone, or format. | Examples may “anchor” or bias the model too heavily toward the sample—even when a better option exists. |
| | **Break Down Complex Tasks** | Avoids overload and improves quality by handling the work in stages. | Have the model do one phase at a time (e.g. outline first, content second). | Adds more back-and-forth steps and may require active guidance between steps. |
| | **Explicit Output Format** | Produces predictable, structured responses that are easy to reuse in automation or reporting. | Asking for a table, bullet points, JSON, etc. to make responses machine-readable. | If the format is too rigid or complex, the model may produce invalid or partially incorrect structure. |
| **Level 3: Advanced (Decision Support & Automation)** | **Recursive Self-Improvement** | Improves quality by having the model review and refine its own responses. | Ask the model to write a draft, critique it, then revise based on the critique. | Self-critique may be shallow unless guided by clear criteria; adds extra output volume. |
| | **Tree-of-Thoughts (ToT)** | Helps explore multiple solutions and evaluate them before choosing a final answer. | Generating several options first, with pros and cons, before selecting the best one. | Can produce redundant or repetitive content. Requires careful review to select the best path forward. |
| | **Constitutional Prompting** | Enforces adherence to rules or guidelines throughout the response. | Embedding rules (like “no jargon,” “always cite sources”) that the model must follow. | Too many rules may confuse or slow the model, and can sometimes conflict or be forgotten without reminders. |
| **Additional Principles (Simpler)** | **Structure & Organize Inputs Clearly** | Makes prompts easy for the model to parse and follow. Combining clear formatting with semantic labels prevents confusion. | Separate instructions, examples, and data using formatting (backticks, headings) and semantic labels (task, context, input, output). | Misuse or inconsistent formatting can lead to confusion; over-structuring may feel rigid to users. |
| | **Embed Examples of Bad Outputs to Avoid** | Guides the model on what not to do, improving output quality. | Show examples of common mistakes or undesired outputs alongside good ones. | Can confuse the model if bad examples are too similar to good ones; requires clear distinction between good and bad. |
| | **Minimise Irrelevant Context** | Reduces hallucinations and keeps the model focused on the task. | Include only necessary background; avoid clutter and irrelevant details. | Users may omit important details by mistake or include too much, overloading the model. |
| | **Set Clear Evaluation Criteria** | Helps judge output quality and guides the model to meet expectations. | Define metrics for correctness, completeness, tone, and format. | Requires users to define success upfront; vague criteria may be ignored or misinterpreted. |
| | **Generate Knowledge First** | Improves accuracy on knowledge-intensive tasks by grounding the model's reasoning. | Ask the model to review what it knows or state its assumptions *before* answering the main question (still single-turn). | If the generated knowledge is incorrect it may anchor errors; requires clarity that this is a review step, not an external lookup. |
| **Additional Principles (Advanced)** | **Adapt to the Model / Version** | Tailoring prompts to the specific model improves output quality. | Adjust phrasing, length, and style depending on the model's capabilities and strengths. | Adds complexity; non-experts may not know model differences; reduces prompt portability. |
| | **Use Meta-Prompting (Structure-Over-Content)** | Emphasizes reusable structural templates over content details, making prompts easier to adapt and standardize. | Focus on the form or template of prompts for repeated tasks, not just the words. | Can feel abstract or too rigid for one-off tasks; may confuse users if not explained clearly. |
